import streamlit as st
import fitz  # PyMuPDF
from docx import Document
from PIL import Image
import pytesseract
import re, io, json, time, math
import pandas as pd
import numpy as np

# ----------------------------
# CONFIG & BRANDING
# ----------------------------
st.set_page_config(
    page_title="EspritCareers",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

PRIMARY = "#E00000"   # Esprit Red
DARK = "#111111"
MUTED = "#6B7280"
BG = "#0B0C10"

st.markdown(f"""
<style>
/* Global */
html, body, [class*="css"]  {{
  font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";
}}
/* Header title */
h1, h2, h3, h4 {{
  letter-spacing: .3px;
}}
/* Cards */
.ec-card {{
  border: 1px solid #1f2937;
  border-radius: 16px;
  padding: 18px 18px 14px;
  background: #0f1115;
}}
/* Primary button */
div.stButton > button:first-child {{
  background-color: {PRIMARY};
  color: #fff; border-radius: 12px; border: none; padding: 8px 14px;
}}
/* Tags */
.badge {{
  display:inline-block; padding:4px 10px; border-radius:999px; background:#111827; color:#e5e7eb; font-size:12px; border:1px solid #1f2937;
}}
.metric-ok {{color:#16a34a}}
.metric-warn {{color:#f59e0b}}
.metric-bad {{color:#ef4444}}
</style>
""", unsafe_allow_html=True)

# ----------------------------
# SIDEBAR (LOGO + NAV)
# ----------------------------
with st.sidebar:
    st.image("assets/esprit_logo.png", use_column_width=True, caption="EspritCareers ‚Ä¢ v2")
    st.markdown("**P√¥le Employabilit√© ‚Äì D√©monstrateur IA**")
    st.markdown('<span class="badge">PDF</span> <span class="badge">DOCX</span> <span class="badge">Image (OCR)</span> <span class="badge">ATS</span> <span class="badge">Entretien</span>', unsafe_allow_html=True)
    st.divider()
    st.markdown("**Guide rapide**")
    st.caption("1) Onglet **CV** : upload, colle l‚Äôoffre, lance l‚Äôanalyse.\n2) **Lettre** : upload/texte, coh√©rence vs offre.\n3) **Entretien** : questions QCM + ouvertes.\n4) **Dashboard** : stats d√©mo.")
    st.divider()
    st.caption("¬© EspritCareers ‚Ä¢ D√©mo acad√©mique")

# ----------------------------
# HELPERS: extraction & NLP light
# ----------------------------
def extract_text_from_file(file):
    name = file.name.lower()
    byts = file.read()
    if name.endswith(".pdf"):
        doc = fitz.open(stream=byts, filetype="pdf")
        text, used_ocr = "", False
        for page in doc:
            t = page.get_text().strip()
            if not t:
                # OCR fallback
                pix = page.get_pixmap(dpi=300)
                img = Image.open(io.BytesIO(pix.tobytes()))
                t = pytesseract.image_to_string(img, lang="fra+eng")
                used_ocr = True
            text += "\n" + t
        return text.strip(), used_ocr
    elif name.endswith(".docx"):
        docx = Document(io.BytesIO(byts))
        return "\n".join(p.text for p in docx.paragraphs), False
    elif name.endswith((".png",".jpg",".jpeg")):
        img = Image.open(io.BytesIO(byts))
        t = pytesseract.image_to_string(img, lang="fra+eng")
        return t.strip(), True
    else:
        return "", False

STOPWORDS = set("""
le la les un une des et √† de du pour par ou au aux en avec sur sous dans d' l' un(e) le/la
a et/ou que qui quoi dont o√π alors ainsi donc or ni car the a an to of in on at for from by with as is are
""".split())

def keyword_candidates(text, top=20):
    # super simple keywording
    tokens = re.findall(r"[a-zA-Z√Ä-√ø0-9\+\#\.]{2,}", text.lower())
    tokens = [t for t in tokens if t not in STOPWORDS and not t.isdigit()]
    freq = pd.Series(tokens).value_counts().head(top)
    return list(freq.index)

def build_job_keywords(job_text):
    cands = keyword_candidates(job_text, top=30)
    # heuristique: must-have = top 10, nice-to-have = suivants
    must = cands[:10]
    nice = cands[10:20]
    return {
        "must_have": must,
        "nice_to_have": nice,
        "weights": {"mh":0.5,"nh":0.2,"struct":0.15,"quant":0.1,"format":0.05}
    }

def normalize(t):
    return re.sub(r"[^a-zA-Z√Ä-√ø0-9\s\-]", " ", t.lower())

def keyword_score(cv_text, must_have, nice_to_have):
    t = normalize(cv_text)
    smh = sum(1 for k in must_have if k.lower() in t)
    snh = sum(1 for k in nice_to_have if k.lower() in t)
    return (smh/ max(1,len(must_have))), (snh/ max(1,len(nice_to_have)))

def quantify_score(cv_text):
    nums = re.findall(r"\b\d+(\.\d+)?%?|\b\d{4}\b", cv_text)
    return min(1.0, len(nums)/8)

def structure_score(cv_text):
    sec = ["profil","summary","exp√©rience","experience","formation","education","comp√©tences","skills","projets","projects"]
    t = normalize(cv_text)
    hits = sum(1 for s in sec if s in t)
    return min(1.0, hits/6)

def ats_score(cv_text, job_kw):
    mh, nh = job_kw["must_have"], job_kw["nice_to_have"]
    w = job_kw.get("weights", {"mh":0.5,"nh":0.2,"struct":0.15,"quant":0.1,"format":0.05})
    smh, snh = keyword_score(cv_text, mh, nh)
    sst = structure_score(cv_text)
    sq  = quantify_score(cv_text)
    sfo = 1.0  # placeholder (lisibilit√©/mise en forme)
    total = 100*(w["mh"]*smh + w["nh"]*snh + w["struct"]*sst + w["quant"]*sq + w["format"]*sfo)
    breakdown = {
        "Must-have": round(100*w["mh"]*smh,1),
        "Nice-to-have": round(100*w["nh"]*snh,1),
        "Structure": round(100*w["struct"]*sst,1),
        "Quantification": round(100*w["quant"]*sq,1),
        "Mise en forme": round(100*w["format"]*sfo,1)
    }
    return round(total,1), breakdown

def suggest_improvements(cv_text, job_kw):
    t = normalize(cv_text)
    missing_mh = [k for k in job_kw["must_have"] if k.lower() not in t][:6]
    suggestions = []
    if missing_mh:
        suggestions.append(f"Ajoute/renforce ces mots-cl√©s indispensables : **{', '.join(missing_mh)}**.")
    if quantify_score(cv_text) < 0.6:
        suggestions.append("Ajoute des **chiffres** (%, ‚Ç¨, d√©lais, volumes) pour quantifier tes r√©alisations.")
    if structure_score(cv_text) < 0.8:
        suggestions.append("V√©rifie les **sections** standards : Profil, Exp√©rience, Formation, Comp√©tences, Projets.")
    suggestions += [
        "Utilise des **verbes d‚Äôaction** : con√ßu, d√©ploy√©, optimis√©, automatis√©, n√©goci√©.",
        "Raccourcis le r√©sum√© en 4‚Äì5 lignes, orient√© **r√©sultats** et **outils**."
    ]
    return suggestions[:5]

def tone_heuristic(letter_text):
    t = letter_text.lower()
    score_formel = int(any(x in t for x in ["madame","monsieur","candidature","motivation","cordialement"])) * 50
    score_concret = min(50, len(re.findall(r"\b\d+%?|\b(kpi|roi|budget|projet|deadline)\b", t))*5)
    return min(100, score_formel + score_concret)

# Session state to collect analyses for dashboard
if "history" not in st.session_state:
    st.session_state["history"] = []

st.title("üéì EspritCareers")
st.caption("Plateforme d‚Äôemployabilit√© ‚Äì **Analyse de CV**, **Lettre de motivation**, **Simulation d‚Äôentretien**, **Dashboard**.")

# ----------------------------
# TABS
# ----------------------------
tab_cv, tab_cover, tab_interview, tab_dash = st.tabs(["üìÑ CV", "‚úâÔ∏è Lettre", "üó£Ô∏è Entretien", "üìä Dashboard"])

# ----------------------------
# TAB: CV
# ----------------------------
with tab_cv:
    st.subheader("Analyse de CV (ATS)")
    colA, colB = st.columns([1,1])
    with colA:
        uploaded_cv = st.file_uploader("T√©l√©verse ton CV (PDF, DOCX ou Image)", type=["pdf","docx","png","jpg","jpeg"], key="cv")
        job_text = st.text_area("Colle ici l‚Äôoffre de poste / mission", placeholder="Colle l'offre (missions, comp√©tences, mots-cl√©s, logiciels‚Ä¶)", height=180)
        run = st.button("üîé Analyser le CV")
    with colB:
        st.markdown('<div class="ec-card">', unsafe_allow_html=True)
        st.markdown("**Conseil**")
        st.caption("Plus l‚Äôoffre est d√©taill√©e, plus le score ATS est pertinent (mots-cl√©s must-have / nice-to-have).")
        st.markdown('</div>', unsafe_allow_html=True)

    if run:
        if not uploaded_cv or not job_text.strip():
            st.error("Ajoute un CV **et** colle l‚Äôoffre de poste, puis relance.")
        else:
            with st.spinner("Extraction du texte‚Ä¶"):
                text, used_ocr = extract_text_from_file(uploaded_cv)

            if len(text) < 80:
                st.error("Le document semble vide ou illisible. Essaie un PDF/DOCX de meilleure qualit√©.")
            else:
                job_kw = build_job_keywords(job_text)
                score, breakdown = ats_score(text, job_kw)

                c1, c2, c3 = st.columns(3)
                c1.metric("üéØ Score ATS", f"{score}/100")
                c2.metric("üìå Must-have couverts", f"{int(round(breakdown['Must-have']/50*len(job_kw['must_have']),0))}/{len(job_kw['must_have'])}")
                c3.metric("üñºÔ∏è OCR utilis√©", "Oui" if used_ocr else "Non")

                st.progress(min(1.0, score/100))
                st.markdown("#### D√©tails du score")
                dfb = pd.DataFrame({"Dimension": list(breakdown.keys()), "Points": list(breakdown.values())})
                st.bar_chart(dfb.set_index("Dimension"))

                st.markdown("#### Suggestions")
                for s in suggest_improvements(text, job_kw):
                    st.markdown(f"- {s}")

                with st.expander("Voir le texte extrait"):
                    st.text_area("Texte extrait", text, height=220)

                # Save to history for dashboard
                st.session_state["history"].append({
                    "ts": time.time(),
                    "type": "cv",
                    "score": score,
                    "breakdown": breakdown
                })

                # Export JSON report
                report = {
                    "score": score,
                    "breakdown": breakdown,
                    "must_have": job_kw["must_have"],
                    "nice_to_have": job_kw["nice_to_have"],
                    "ocr_used": used_ocr
                }
                st.download_button(
                    "üì• T√©l√©charger le rapport (JSON)",
                    data=json.dumps(report, ensure_ascii=False, indent=2).encode("utf-8"),
                    file_name="rapport_ats.json",
                    mime="application/json"
                )

# ----------------------------
# TAB: Lettre
# ----------------------------
with tab_cover:
    st.subheader("Lettre de motivation ‚Äì Coh√©rence & Ton")
    lc1, lc2 = st.columns([1,1])
    with lc1:
        uploaded_letter = st.file_uploader("T√©l√©verse ta lettre (PDF, DOCX ou Image)", type=["pdf","docx","png","jpg","jpeg"], key="cover")
        letter_text_input = st.text_area("‚Ä¶ou colle le texte ici", height=220)
    with lc2:
        job_text_cover = st.text_area("Colle l‚Äôoffre de poste (r√©f√©rence pour la coh√©rence)", height=220, key="job_cover")
        analyze_cover = st.button("üß† Analyser la lettre")

    if analyze_cover:
        if not uploaded_letter and not letter_text_input.strip():
            st.error("Ajoute un fichier **ou** colle le texte de la lettre.")
        elif not job_text_cover.strip():
            st.error("Colle l‚Äôoffre pour √©valuer la coh√©rence.")
        else:
            if uploaded_letter:
                text_letter, _ = extract_text_from_file(uploaded_letter)
            else:
                text_letter = letter_text_input

            if len(text_letter) < 60:
                st.error("La lettre semble trop courte / illisible.")
            else:
                kw_job = set(build_job_keywords(job_text_cover)["must_have"])
                overlap = [k for k in kw_job if k in normalize(text_letter)]
                coh = min(100, int(len(overlap)/max(1,len(kw_job))*100))
                ton = tone_heuristic(text_letter)

                mc1, mc2 = st.columns(2)
                mc1.metric("üîó Coh√©rence vs offre", f"{coh}/100")
                mc2.metric("üóíÔ∏è Ton & structure", f"{ton}/100")
                st.progress(min(1.0, (coh+ton)/200))

                st.markdown("#### Recommandations")
                if coh < 70:
                    st.markdown("- Aligne mieux ta lettre sur les **mots-cl√©s** et missions de l‚Äôoffre.")
                if ton < 70:
                    st.markdown("- Renforce le **ton formel** et ajoute des **exemples chiffr√©s** (r√©sultats, KPIs).")
                st.markdown("- Utilise la structure : *Intro* ‚Üí *Motivation/valeur ajout√©e* ‚Üí *Exemples* ‚Üí *Conclusion polie*.")

                with st.expander("Voir le texte de la lettre"):
                    st.text_area("Lettre", text_letter, height=220)

                st.session_state["history"].append({
                    "ts": time.time(),
                    "type": "letter",
                    "coherence": coh,
                    "tone": ton
                })

# ----------------------------
# TAB: Entretien
# ----------------------------
with tab_interview:
    st.subheader("Simulation d‚Äôentretien")
    role = st.selectbox("R√¥le cibl√©", ["Business Analyst", "Data Analyst", "PMO Junior", "Marketing Analyst", "D√©veloppeur Python"])
    level = st.selectbox("Niveau", ["Junior", "Interm√©diaire"])
    focus = st.multiselect("Focus", ["SQL", "Python", "Excel/BI", "Gestion de projet", "Communication", "Produit"])
    gen = st.button("üé§ G√©n√©rer des questions")

    if gen:
        qcm = []
        openq = []
        # QCM simple en fonction du focus
        if "SQL" in focus:
            qcm.append({"q":"Quelle requ√™te renvoie les 10 derni√®res lignes d'une table `orders` ?", 
                        "opts":["SELECT * FROM orders LIMIT 10;",
                                "SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;",
                                "SELECT TOP 10 * FROM orders;"],
                        "correct":1})
        if "Python" in focus:
            qcm.append({"q":"Quel objet stocke des paires cl√©/valeur en Python ?", 
                        "opts":["list","tuple","dict"], "correct":2})
        if "Gestion de projet" in focus:
            qcm.append({"q":"Dans SCRUM, qui priorise le backlog ?", 
                        "opts":["Scrum Master","Product Owner","D√©veloppeur"], "correct":1})

        openq += [
            {"q": "Donne un exemple **STAR** o√π tu as am√©lior√© un KPI cl√©."},
            {"q": "Comment g√®res-tu un stakeholder **difficile** ?"},
            {"q": "D√©cris une **analyse** dont l‚Äôimpact a √©t√© mesur√© (temps, co√ªts, qualit√©)."}
        ]

        st.markdown("#### QCM")
        score_qcm = 0
        for i, item in enumerate(qcm):
            st.write(f"**Q{i+1}.** {item['q']}")
            ans = st.radio("R√©ponse :", item["opts"], key=f"qcm{i}")
            if st.button(f"V√©rifier Q{i+1}", key=f"chk{i}"):
                idx = item["opts"].index(ans)
                if idx == item["correct"]:
                    st.success("‚úîÔ∏è Correct")
                    score_qcm += 1
                else:
                    st.error(f"‚ùå Mauvaise r√©ponse. Bonne r√©ponse : **{item['opts'][item['correct']]}**")

        st.markdown("#### Questions ouvertes (guide)")
        for j, q in enumerate(openq):
            st.write(f"- {q['q']}")

        st.info("Astuce : R√©ponds en **STAR** (Situation, T√¢che, Action, R√©sultat) et **quantifie** ton impact.")

# ----------------------------
# TAB: Dashboard
# ----------------------------
with tab_dash:
    st.subheader("Dashboard ‚Äì D√©mo")
    hist = st.session_state.get("history", [])
    if not hist:
        st.caption("Les r√©sultats de tes analyses s‚Äôafficheront ici.")
    else:
        df = pd.DataFrame(hist)
        c1, c2 = st.columns(2)
        with c1:
            st.metric("Analyses r√©alis√©es", len(df))
        with c2:
            if "score" in df.columns:
                st.metric("Score ATS moyen", f"{round(df['score'].dropna().mean(),1)} / 100")
        st.markdown("#### Historique (table)")
        st.dataframe(df.fillna("-"))
        st.markdown("#### R√©partition par type")
        counts = df["type"].value_counts()
        st.bar_chart(counts)

# ----------------------------
# END
# ----------------------------
